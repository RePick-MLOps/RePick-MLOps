from langchain_community.vectorstores import Chroma, FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain.retrievers import BM25Retriever, EnsembleRetriever
from langchain_core.documents import Document


def load_embedding_model(model_name="jhgan/ko-sbert-sts"):
    return HuggingFaceEmbeddings(model_name=model_name)


def load_vectorstore(vectordb_path):
    try:
        embeddings = load_embedding_model()
        vectorstore = Chroma(
            persist_directory="s3://repick-chromadb/vectordb",
            embedding_function=embeddings,
            collection_name="pdf_collection",
        )

        # ë°ì´í„° ìƒì„¸ í™•ì¸
        collection = vectorstore._collection.get()
        print(f"\n=== Chroma DB ìƒíƒœ ===")
        print(
            f"ì´ ë¬¸ì„œ ìˆ˜: {len(collection['documents']) if collection['documents'] else 0}"
        )
        print(f"ì»¬ë ‰ì…˜ ì´ë¦„: pdf_collection")

        return vectorstore
    except Exception as e:
        print(f"Error loading vector store: {str(e)}")
        raise


def create_prompt():
    return PromptTemplate.from_template(
        """You are an assistant for question-answering tasks. 
Use the following pieces of retrieved context to answer the question. 
If you don't know the answer, just say that you don't know. 
Answer in Korean.

# Direction:
Make sure you understand the intent of the question and provide the most appropriate answer.
- Ask yourself the context of the question and why the questioner asked it, think about the question, and provide an appropriate answer based on your understanding.
2. Select the most relevant content (the key content that directly relates to the question) from the context in which it was retrieved to write your answer.
3. Create a concise and logical answer. When creating your answer, don't just list your selections, but rearrange them to fit the context so they flow naturally into paragraphs.
4. If you haven't searched for context for the question, or if you've searched for a document but its content isn't relevant to the question, you should say 'I can't find an answer to that question in the materials I have'.
5. Write your answer in a table of key points.
6. Your answer must include all sources and page numbers.
7. Your answer must be written in Korean.
8. Be as detailed as possible in your answer.
9. Begin your answer with 'This answer is based on content found in the document **' and end with '**ğŸ“Œ source**'.
10. Page numbers should be whole numbers.

#Context: 
{context}

###

#Example Format:
**ğŸ“š ë¬¸ì„œì—ì„œ ê²€ìƒ‰í•œ ë‚´ìš©ê¸°ë°˜ ë‹µë³€ì…ë‹ˆë‹¤**

(brief summary of the answer)
(include table if there is a table in the context related to the question)
(include image explanation if there is a image in the context related to the question)
(detailed answer to the question)

**ğŸ“Œ ì¶œì²˜**
[here you only write filename(.pdf only), page]

- íŒŒì¼ëª….pdf, 192ìª½
- íŒŒì¼ëª….pdf, 192ìª½
- ...

###

#Question:
{question}

#Answer:"""
    )


def create_chain(retriever):
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

    def retrieve_and_format(question: str) -> str:
        try:
            # ë¬¸ì„œ ê²€ìƒ‰
            docs = retriever.get_relevant_documents(question)

            # ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
            context = "\n\n".join(doc.page_content for doc in docs)

            # ë©”íƒ€ë°ì´í„° ì •ë³´ ì¶”ê°€
            sources = []
            for doc in docs:
                if doc.metadata.get("source") and doc.metadata.get("page"):
                    sources.append(
                        f"- {doc.metadata['source']}, {doc.metadata['page']}ìª½"
                    )

            if sources:
                context += "\n\nì¶œì²˜:\n" + "\n".join(sources)

            return context

        except Exception as e:
            print(f"Error in retrieve_and_format: {str(e)}")
            return "ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    chain = (
        {
            "context": RunnableLambda(retrieve_and_format),
            "question": RunnablePassthrough(),
        }
        | create_prompt()
        | llm
        | StrOutputParser()
    )

    return chain


def initialize_retrievers(all_docs):
    # BM25 ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
    bm25_retriever = BM25Retriever.from_documents(all_docs)
    bm25_retriever.k = 5

    # FAISS ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
    embedding = OpenAIEmbeddings()
    faiss_vectorstore = FAISS.from_documents(all_docs, embedding)
    faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={"k": 5})

    # ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
    ensemble_retriever = EnsembleRetriever(
        retrievers=[bm25_retriever, faiss_retriever],
        weights=[0.7, 0.3],
    )

    return ensemble_retriever


def clean_retrieved_documents(retrieved_documents):
    clean_docs = []

    for doc in retrieved_documents:
        # Document ê°ì²´ê°€ ì•„ë‹Œ ê²½ìš° ê±´ë„ˆë›°ê¸°
        if not hasattr(doc, "metadata") or not hasattr(doc, "page_content"):
            continue

        metadata = doc.metadata
        new_metadata = {}
        content = doc.page_content

        if isinstance(content, dict):
            # contentê°€ dictì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
            content = str(content)

        if metadata.get("type") in ["page_summary", "text"]:
            if "page" in metadata:
                new_metadata["page"] = metadata["page"]
            if "source" in metadata:
                new_metadata["source"] = metadata["source"]
            if metadata.get("type") == "text" and "summary" in metadata:
                new_metadata["summary"] = metadata["summary"]
            clean_docs.append(Document(page_content=content, metadata=new_metadata))

        elif metadata.get("type") == "hypothetical_questions":
            content = metadata.get("summary", content)
            if "page" in metadata:
                new_metadata["page"] = metadata["page"]
            if "source" in metadata:
                new_metadata["source"] = metadata["source"]
            clean_docs.append(Document(page_content=content, metadata=new_metadata))

    return clean_docs


def retrieve_and_check(question, ensemble_retriever):
    retrieved_documents = ensemble_retriever.invoke(question)
    cleaned_documents = clean_retrieved_documents(retrieved_documents)
    return cleaned_documents


def test_chatbot():
    vectorstore = load_vectorstore("/Users/naeun/working/RePick-MLOps/data/vectordb")
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 4},
        collection_name="pdf_collection",
    )

    qa_chain = create_chain(retriever)
    return qa_chain
